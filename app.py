import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import plotly.figure_factory as ff
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
import scipy.stats as stats
import pickle

# Configuraci√≥n de la p√°gina

st.set_page_config(page_title="EDA Cancer",
                   page_icon="üìä",
                   layout="wide")

# Datos

datos = pd.read_csv('data.csv')

X = datos.drop(columns=["id", "diagnosis"])
feature_names = X.columns.tolist()
y = datos["diagnosis"]
df = pd.DataFrame(X, columns=feature_names)
df["Diagn√≥stico"] = y.map({"M": "Maligno", "B": "Benigno"})

# T√≠tulo y descripci√≥n

st.title("An√°lisis Exploratorio de Datos - Breast Cancer (Wisconsin)")

st.markdown("""
        Este an√°lisis permite explorar las caracter√≠sticas m√°s relevantes del dataset Breast Cancer Wisconsin Diagnostic, 
        proporcionando visualizaciones y estad√≠sticas descriptivas para facilitar la comprensi√≥n del comportamiento de cada variable 
        seg√∫n el diagn√≥stico.
    """)

st.markdown("""
    <div style="text-align: justify;">
        Este an√°lisis permite explorar las caracter√≠sticas m√°s relevantes del dataset <strong>Breast Cancer Wisconsin Diagnostic</strong>, 
        proporcionando visualizaciones y estad√≠sticas descriptivas para facilitar la comprensi√≥n del comportamiento de cada variable 
        seg√∫n el diagn√≥stico.
    </div>
    """, unsafe_allow_html=True)

st.subheader("Primeras filas del dataset")
st.dataframe(df.head(6))
st.markdown("""
    <div style="text-align: justify;">
        Tras llevar a cabo un an√°lisis exploratorio inicial del conjunto de datos, se verific√≥ la ausencia de valores faltantes en las variables consideradas. 
    </div>
    """, unsafe_allow_html=True)

# Separador
st.markdown("""
---
""")

# -----------------------------
# Datos faltantes en el dataset
# -----------------------------


#st.subheader("Conteo de datos faltantes en el dataset")

#valores_nulos = df.isnull().sum()

#tabla_nulos = pd.DataFrame({
#    'Variable': valores_nulos.index,
#    'Cantidad de valores faltantes': valores_nulos.values
#})

#st.markdown("""
#    <div style="text-align: justify;">
#        Como se evidencia en la presente tabla, vemos que no hay valores faltantes en el dataset.
#    </div>
#    """, unsafe_allow_html=True)

#st.table(tabla_nulos)


# Sidebar

st.sidebar.header('Variables de estudio')
variables = df.columns.drop("Diagn√≥stico")
variable_seleccionada = st.sidebar.selectbox('Por favor, seleccione la variable de inter√©s!', variables)

# Autor

with st.sidebar:
    st.markdown("""
    <hr>
    <div style="text-align: center; font-size: 0.9em; color: gray;">
        Desarrollado por Carlos D. L√≥pez P.
    </div>
    """, unsafe_allow_html=True)




# T√≠tulo variable seleccionada
#st.markdown(f"## An√°lisis de la variable: {variable_seleccionada}")
st.markdown(f"## An√°lisis de la variable: <span style='color:#2a9df4; font-weight:bold'>{variable_seleccionada}</span>", unsafe_allow_html=True)

# Subconjunto de datos
valores = df[variable_seleccionada]
diagnostico = df['Diagn√≥stico']

# Gr√°ficos
st.subheader("Distribuci√≥n de la variable")
st.markdown("""
    <div style="text-align: justify;">
        A continuacion se presenta un histograma y un diagrama de caja y bigotes interactivos de la variable seleccionada por tipo de diagnostico
    </div>
    """, unsafe_allow_html=True)


# -----------------------------
# Figuras y ejemplos
# -----------------------------

#fig, ax = plt.subplots()
#ax.hist(df[variable_seleccionada], bins=30, color="steelblue", edgecolor="black")
#ax.set_title("Histograma 1", fontsize=14)
#ax.set_xlabel(variable_seleccionada, fontsize=12)
#ax.set_ylabel("Frecuencia", fontsize=12)
#st.pyplot(fig)


#figura = px.histogram(
#        df,
#        x=variable_seleccionada,
#        nbins=30,
#        marginal="rug",
#        title="Histograma 1",
#        color_discrete_sequence=["steelblue"]
#    )
#    
#figura.update_traces(marker=dict(line=dict(color="black", width=1)))  # L√≠nea negra alrededor de las barras
#st.plotly_chart(figura, use_container_width=True)

col1, col2 = st.columns(2)

# Histograma
with col1:
    fig = px.histogram(
        df,
        x=variable_seleccionada,
        nbins=30,
        marginal="rug",
        title="Histograma",
        color_discrete_sequence=["steelblue"]
    )
    
    fig.update_traces(marker=dict(line=dict(color="black", width=1)))  # L√≠nea negra alrededor de las barras
    
    st.plotly_chart(fig, use_container_width=True)

# Boxplot con colores personalizados
with col2:
    fig2 = px.box(
        df,
        x='Diagn√≥stico',
        y=variable_seleccionada,
        color='Diagn√≥stico',
        title="Boxplot por Diagn√≥stico",
        color_discrete_map={
            'Benigno': 'steelblue',  # Azul para 'Benigno'
            'Maligno': 'firebrick'    # Rojo para 'Maligno'
        }
    )
    st.plotly_chart(fig2, use_container_width=True)

# Filtrar los datos por diagn√≥stico
grupo_benigno = df[df['Diagn√≥stico'] == 'Benigno'][variable_seleccionada].dropna()
grupo_maligno = df[df['Diagn√≥stico'] == 'Maligno'][variable_seleccionada].dropna()

# Prueba t de Student para muestras independientes
t_stat, p_valor = stats.ttest_ind(grupo_benigno, grupo_maligno, equal_var=False)  # Welch‚Äôs t-test

# Resultados
st.subheader("Comparaci√≥n de medias por diagn√≥stico")
st.markdown(f"""
<div style="text-align: justify;">
    Se realiz√≥ una prueba t de Student para comparar las medias de la variable <strong>{variable_seleccionada}</strong> entre los grupos <strong>Benigno</strong> y <strong>Maligno</strong>.
    El valor p obtenido fue <strong>{p_valor:.4f}</strong>. {"Esto indica una diferencia significativa entre los grupos." if p_valor < 0.05 else "No se encontraron diferencias significativas entre los grupos."}
</div>
""", unsafe_allow_html=True)



# Estad√≠sticas descriptivas
st.subheader("Estad√≠sticas Descriptivas")
st.dataframe(valores.describe().to_frame().T.round(2))


# Comparaci√≥n por diagn√≥stico
st.markdown(f"### Resumen de <span style='color:#2a9df4; font-weight:bold'>{variable_seleccionada}</span> por tipo de diagn√≥stico", unsafe_allow_html=True)
st.write(df.groupby("Diagn√≥stico")[variable_seleccionada].describe())


st.markdown("""
---
""")

# Gr√°fico de dispersi√≥n con otras variables
st.subheader("Relaci√≥n con otras variables")
otras_variables = [var for var in variables if var != variable_seleccionada]
otra_variable = st.selectbox("Seleccione otra variable para comparar", otras_variables)

fig3 = px.scatter(
    df,
    x=variable_seleccionada,
    y=otra_variable,
    color='Diagn√≥stico',
    title="Gr√°fico de dispersi√≥n interactivo",
    color_discrete_sequence=px.colors.qualitative.Set1,
    hover_data=df.columns
)

st.plotly_chart(fig3, use_container_width=True)


# Tabla de datos
st.subheader("Vista previa de los datos")
st.dataframe(df[[variable_seleccionada, otra_variable, 'Diagn√≥stico']].head(6))

# Correlacion


st.markdown("""
---
""")


st.subheader("Matriz de correlaci√≥n entre las variables de estudio")
st.markdown("""
    <div style="text-align: justify;">
        A continuaci√≥n, se presenta la matriz de correlaci√≥n, la cual permite identificar la intensidad y direcci√≥n de las relaciones entre las variables num√©ricas del dataset. Este an√°lisis resulta √∫til para detectar posibles asociaciones relevantes que podr√≠an influir en el modelado posterior.
    </div>
    """, unsafe_allow_html=True)

# Copia del DataFrame y codificaci√≥n
df_temp = df.copy()
df_temp['Diagn√≥stico'] = df_temp['Diagn√≥stico'].map({'Benigno': 0, 'Maligno': 1})

# Filtrado num√©rico y c√°lculo de correlaci√≥n
df_numericas = df_temp.select_dtypes(include=[float, int])
matriz_correlacion = df_numericas.corr()

# Forzamos la diagonal a 1
np.fill_diagonal(matriz_correlacion.values, 1)

# Heatmap sin anotaciones
fig_corr = go.Figure(
    data=go.Heatmap(
        z=matriz_correlacion.values,
        x=matriz_correlacion.columns,
        y=matriz_correlacion.index,
        colorscale='RdYlBu_r',
        zmin=-1, zmax=1,
        showscale=True
    )
)

fig_corr.update_layout(
    width=1000,
    height=600,
    margin=dict(l=100, r=20, t=30, b=30),
    xaxis=dict(tickangle=45),
    yaxis=dict(autorange='reversed')  # opcional: mantiene orden original
)

st.plotly_chart(fig_corr, use_container_width=False)



st.markdown("""
## üîç An√°lisis de Correlaciones

El siguiente mapa de calor representa las correlaciones entre las variables del conjunto de datos, incluyendo la variable objetivo **`Diagn√≥stico`**.

### üìå Conclusiones principales

---

### üîπ 1. Fuertes correlaciones entre ciertas variables
- Variables como `radius_mean`, `perimeter_mean` y `area_mean` muestran una **fuerte correlaci√≥n positiva** entre s√≠.
- Este patr√≥n tambi√©n se repite en sus versiones `_worst`: `radius_worst`, `perimeter_worst`, `area_worst`.
- Es esperable, ya que est√°n relacionadas geom√©tricamente: un mayor radio implica mayor per√≠metro y mayor √°rea.

---

### üîπ 2. Posible multicolinealidad
- Se observan correlaciones altas entre variables similares medidas en distintas etapas (por ejemplo, `radius_mean`, `radius_se`, `radius_worst`).
- Esta redundancia sugiere **potencial multicolinealidad**, que puede afectar negativamente a algunos modelos como la regresi√≥n log√≠stica.
- T√©cnicas como **PCA (An√°lisis de Componentes Principales)** o m√©todos de selecci√≥n de variables pueden ayudar a mitigar este problema.

---

### üîπ 3. Correlaci√≥n con el `Diagn√≥stico`
- Algunas variables tienen una **correlaci√≥n positiva clara con el diagn√≥stico maligno**:
  - `concave points_mean`, `concavity_mean`, `radius_mean`, `perimeter_mean`, `area_mean`
  - Tambi√©n sus equivalentes `_worst` y algunas `_se`.
- Esto sugiere que a medida que aumentan estos valores, **es m√°s probable que el diagn√≥stico sea maligno**.
- Estas variables son buenas candidatas para modelos de clasificaci√≥n.

---

### üîπ 4. Variables menos correlacionadas
- Variables como `fractal_dimension_mean`, `fractal_dimension_se`, y `symmetry_mean` presentan **baja o nula correlaci√≥n con el diagn√≥stico**.
- Aunque esto puede sugerir menor relevancia, **no se deben descartar sin una evaluaci√≥n m√°s profunda**, ya que algunas variables pueden tener relaciones no lineales con el diagn√≥stico.

---
""")

# =====================
# Modelo interno
# =====================

st.title("üßÆ Prediccion del tipo de tumor - Entrenado al incluir variables")

st.markdown("""
<div style="text-align: justify;">
A continuaci√≥n, puedes seleccionar un conjunto de variables para construir un modelo de regresi√≥n log√≠stica, por defecto se seleccionara la media del area, perimetro, concavidad y radio pero puedes eliminarlas o seleccionar mas variables. Una vez entrenado, podr√°s realizar predicciones de diagn√≥stico sobre nuevos datos ingresados manualmente.
</div>
""", unsafe_allow_html=True)


variables_por_defecto = ["radius_mean", "perimeter_mean", "area_mean", "concavity_mean"]

# Mostrar multiselect con preselecci√≥n
variables_predictoras = st.multiselect(
    "",
    df.columns.drop("Diagn√≥stico"),
    default=[var for var in variables_por_defecto if var in df.columns]
)

# Selecci√≥n de variables predictoras
# variables_predictoras = st.multiselect("Selecciona las variables para el modelo", df.columns.drop("Diagn√≥stico"))

if len(variables_predictoras) > 0:
    # Divisi√≥n de los datos
    X = df[variables_predictoras]
    y = df['Diagn√≥stico'].map({"Benigno": 0, "Maligno": 1})

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Entrenar el modelo
    modelo = LogisticRegression(max_iter=1000)
    modelo.fit(X_train, y_train)

    # Evaluaci√≥n del modelo
    st.subheader("Reporte del Modelo")
    y_pred = modelo.predict(X_test)
    report = classification_report(y_test, y_pred, output_dict=True)
    st.dataframe(pd.DataFrame(report).transpose().round(2))

    # Predicci√≥n individual
    st.markdown("""
    ---
    ### üß™ Valores para Predicci√≥n
    Ingresa los valores para cada variable seleccionada:
    """)

    input_data = {}
    for var in variables_predictoras:
        input_data[var] = st.number_input(var, min_value=float(0), max_value=float(10000), value=float(df[var].mean()))

    if st.button("Predecir Diagn√≥stico"):
        input_df = pd.DataFrame([input_data])
        prediccion = modelo.predict(input_df)[0]
        probabilidad = modelo.predict_proba(input_df)[0][1]

        if prediccion == 1:
            st.markdown(f"<span style='color:red; font-weight:bold;'>‚úÖ Diagn√≥stico predicho: Maligno üî¥</span>", unsafe_allow_html=True)
            st.markdown(f"<span style='color:red;'>üî¨ Probabilidad de ser maligno: {probabilidad:.2%}</span>", unsafe_allow_html=True)
        else:
            st.markdown(f"<span style='color:green; font-weight:bold;'>‚úÖ Diagn√≥stico predicho: Benigno üü¢</span>", unsafe_allow_html=True)
            st.markdown(f"Probabilidad de ser maligno: <span style='color:red;'>üî¨  {str(round(probabilidad * 100, 2)) + '%'}</span>", unsafe_allow_html=True)
else:
    st.info("Selecciona al menos una variable para entrenar el modelo.")


st.markdown("""
---
""")

st.title("ü©∫ Predicci√≥n de C√°ncer de Mama cargando un modelo Pickle")

# =====================
# Carga del pickle
# =====================

with open("modelo_cancer.pkl", "rb") as archivos:
    data = pickle.load(archivos)

modelo = data["modelo"]
features = data["features"]

st.write("Introduce los valores de las caracter√≠sticas:")


# =====================
# Crear inputs con valores por defecto en la media
# =====================

medias = datos.drop(columns=["id", "diagnosis"]).mean()

entrada_usuario = {}
for col in features:
    entrada_usuario[col] = st.number_input(
        f"{col}",
        value=float(medias[col]),   # valor medio por defecto
        format="%.4f"
    )

# =====================
# Predicci√≥n
# =====================
if st.button("Predecir"):
    X_new = pd.DataFrame([entrada_usuario], columns=features)
    pred = modelo.predict(X_new)[0]
    proba_benigno = modelo.predict_proba(X_new)[0][0]  # solo probabilidad de Benigno

    # Asignar color seg√∫n el nivel de probabilidad
    if proba_benigno >= 0.75:
        color = "green"
    elif proba_benigno >= 0.50:
        color = "orange"
    else:
        color = "red"

    # Mostrar resultado con colores
    st.subheader("Resultado de la Predicci√≥n")
    st.markdown(
        f"""
        <div style="padding:15px; border-radius:10px; background-color:{color}; text-align:center; color:white; font-size:20px;">
            üîé El tumor es: <strong>{pred}</strong><br>
            Probabilidad Benigno: {proba_benigno:.2f}
        </div>
        """,
        unsafe_allow_html=True

    )